# -*- coding: utf-8 -*-
"""Salinan ready to deploy (pipeline).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1TiVUCDP3zuwtB0v82WJ5fUu8Bia1kO8G
"""

#Import Library
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import accuracy_score
import math
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import classification_report
from sklearn.preprocessing import OneHotEncoder
import pickle

#Import Dataset
df = pd.read_csv("https://raw.githubusercontent.com/dJull/Tugas-Akhir-Naive-Bayes-API-Integration/master/loans_full_schema.csv ")


attr = ['homeownership','annual_income','debt_to_income','loan_purpose','loan_amount','balance','term', 'interest_rate', 'grade']
df = df[attr]


# Splitting dataset to X and y
X = df.drop(columns="grade")
y = df['grade']

X_train = pd.read_csv("https://raw.githubusercontent.com/dJull/Tugas-Akhir-Naive-Bayes-API-Integration/master/x_train_70_30_for_tuning.csv")
X_test= pd.read_csv("https://raw.githubusercontent.com/dJull/Tugas-Akhir-Naive-Bayes-API-Integration/master/x_test_70_30_for_tuning.csv")
X_val = pd.read_csv("https://raw.githubusercontent.com/dJull/Tugas-Akhir-Naive-Bayes-API-Integration/master/x_val_70_30_for_tuning.csv")
y_train = pd.read_csv("https://raw.githubusercontent.com/dJull/Tugas-Akhir-Naive-Bayes-API-Integration/master/y_train_70_30_for_tuning.csv")
y_test = pd.read_csv("https://raw.githubusercontent.com/dJull/Tugas-Akhir-Naive-Bayes-API-Integration/master/y_test_70_30_for_tuning.csv")
y_val= pd.read_csv("https://raw.githubusercontent.com/dJull/Tugas-Akhir-Naive-Bayes-API-Integration/master/y_val_70_30_for_tuning.csv")

# Create pipeline for numerical
numerical_pipeline = Pipeline([
    ('numerical_imputation', SimpleImputer(strategy="mean")),
    ('scaler', StandardScaler())
    ])

# Create pipeline for categorical
categorical_pipeline = Pipeline([
    ('categorical_imputation', SimpleImputer(strategy="most_frequent")),
    ('encoder', OneHotEncoder(handle_unknown='ignore')),
    ])

# Create column transform
transform = ColumnTransformer([
    ('categoric', categorical_pipeline, ["homeownership", "loan_purpose"]),
    ('numeric', numerical_pipeline, ["annual_income","debt_to_income","loan_amount","balance","term","interest_rate"])
    ], remainder='passthrough')

# Create pipeline for algorithm
pipeline = Pipeline([
    ('prep', transform),
    ('algo', GaussianNB(var_smoothing = 0.008841631357822753))
])

# Fit Transform X_train and y_train
pipeline.fit(X_train,y_train.grade)
model_score = pipeline.score(X_val,y_val)
# Prediction
y_pred = pipeline.predict(X_val)

# Evaluation
print(round(model_score,2))
print(classification_report(y_val.grade,y_pred))

pickle.dump(pipeline,open("model.pkl","wb"))